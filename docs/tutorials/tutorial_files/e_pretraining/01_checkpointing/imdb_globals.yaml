basic_experiment:
  batch_size: 64
  dataloader_workers: 0
  device: cpu
  memory_dataset: true
  n_epochs: 5
  output_folder: eir_tutorials/tutorial_runs/e_pretraining/01_checkpointing
  valid_size: 1024
evaluation_checkpoint:
  checkpoint_interval: 200
  n_saved_models: 1
  sample_interval: 200
optimization:
  lr: 0.0005
  optimizer: adabelief
visualization_logging:
  plot_skip_steps: 0
